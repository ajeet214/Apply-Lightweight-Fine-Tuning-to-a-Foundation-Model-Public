{
  "best_metric": 0.3374706208705902,
  "best_model_checkpoint": "./results/peft_model/checkpoint-4000",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03,
      "learning_rate": 0.0005,
      "loss": 2.9283,
      "step": 100
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.001,
      "loss": 1.596,
      "step": 200
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0015,
      "loss": 1.2634,
      "step": 300
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.002,
      "loss": 1.1022,
      "step": 400
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0019444444444444444,
      "loss": 1.0489,
      "step": 500
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.001888888888888889,
      "loss": 1.016,
      "step": 600
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0018333333333333333,
      "loss": 0.9824,
      "step": 700
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0017777777777777776,
      "loss": 0.9346,
      "step": 800
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0017222222222222224,
      "loss": 0.8492,
      "step": 900
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0016666666666666668,
      "loss": 0.8406,
      "step": 1000
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0016111111111111111,
      "loss": 0.9244,
      "step": 1100
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0015555555555555557,
      "loss": 0.6864,
      "step": 1200
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0015,
      "loss": 0.8051,
      "step": 1300
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0014444444444444444,
      "loss": 0.7383,
      "step": 1400
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001388888888888889,
      "loss": 0.8062,
      "step": 1500
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0013333333333333333,
      "loss": 0.6961,
      "step": 1600
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0012777777777777776,
      "loss": 0.6321,
      "step": 1700
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0012222222222222224,
      "loss": 0.7962,
      "step": 1800
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0011666666666666668,
      "loss": 0.5505,
      "step": 1900
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0011111111111111111,
      "loss": 0.4605,
      "step": 2000
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0010555555555555557,
      "loss": 0.5148,
      "step": 2100
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001,
      "loss": 0.4819,
      "step": 2200
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0009444444444444445,
      "loss": 0.5356,
      "step": 2300
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0008888888888888888,
      "loss": 0.5574,
      "step": 2400
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0008333333333333334,
      "loss": 0.5809,
      "step": 2500
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0007777777777777778,
      "loss": 0.3874,
      "step": 2600
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0007222222222222222,
      "loss": 0.3233,
      "step": 2700
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0006666666666666666,
      "loss": 0.359,
      "step": 2800
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0006111111111111112,
      "loss": 0.4279,
      "step": 2900
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0005555555555555556,
      "loss": 0.6056,
      "step": 3000
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0005,
      "loss": 0.3417,
      "step": 3100
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0004444444444444444,
      "loss": 0.5209,
      "step": 3200
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0003888888888888889,
      "loss": 0.453,
      "step": 3300
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0003333333333333333,
      "loss": 0.4104,
      "step": 3400
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0002777777777777778,
      "loss": 0.2516,
      "step": 3500
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0002222222222222222,
      "loss": 0.2559,
      "step": 3600
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.00016666666666666666,
      "loss": 0.4293,
      "step": 3700
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0001111111111111111,
      "loss": 0.3862,
      "step": 3800
    },
    {
      "epoch": 0.97,
      "learning_rate": 5.555555555555555e-05,
      "loss": 0.4305,
      "step": 3900
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0,
      "loss": 0.3715,
      "step": 4000
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9215,
      "eval_f1_score": 0.9210827282146451,
      "eval_loss": 0.3374706208705902,
      "eval_precision": 0.9215473462323768,
      "eval_recall": 0.9215,
      "eval_runtime": 78.2501,
      "eval_samples_per_second": 25.559,
      "eval_steps_per_second": 6.39,
      "step": 4000
    }
  ],
  "logging_steps": 100,
  "max_steps": 4000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 4188373254144000.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
